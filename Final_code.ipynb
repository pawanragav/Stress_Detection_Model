{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15e7843-3a14-40cf-9d8c-d83a8e526ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36332f25-f89b-43e4-a105-360b7da9b44a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\tharu\\\\Documents\\\\Minor Project\\\\fer2013'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtharu\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMinor Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfer2013\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\tharu\\\\Documents\\\\Minor Project\\\\fer2013'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\tharu\\Documents\\Minor Project\\fer2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a56aec-c1cd-4e6d-a892-8161ecd91ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff60962-96eb-4724-9da3-881d0b500d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c6def-780f-48da-a83b-87d9e1faae1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "emotion_counts = data['emotion'].value_counts(sort=False).reset_index()\n",
    "emotion_counts.columns = ['emotion', 'number']\n",
    "emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9178000-45a8-44e7-a143-a0ae6733a211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(emotion_counts.emotion, emotion_counts.number)\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('Number', fontsize=12)\n",
    "plt.xlabel('Emotions', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bb06c-ecd1-40c6-a332-9a7e3db7c22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row2image(row):\n",
    "    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n",
    "    img = np.array(pixels.split())\n",
    "    img = img.reshape(48,48)\n",
    "    image = np.zeros((48,48,3))\n",
    "    image[:,:,0] = img\n",
    "    image[:,:,1] = img\n",
    "    image[:,:,2] = img\n",
    "    return np.array([image.astype(np.uint8), emotion])\n",
    "\n",
    "plt.figure(0, figsize=(16,10))\n",
    "for i in range(1,8):\n",
    "    face = data[data['emotion'] == i-1].iloc[0]\n",
    "    img = row2image(face)\n",
    "    plt.subplot(2,4,i)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(img[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86fbb4-601c-4498-8d88-8132c6d16f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split data into training, validation and test set\n",
    "data_train = data[data['Usage']=='Training'].copy()\n",
    "data_val   = data[data['Usage']=='PublicTest'].copy()\n",
    "data_test  = data[data['Usage']=='PrivateTest'].copy()\n",
    "#data_train = data_train[data_train['emotion']!=1]\n",
    "#data_val = data_val[data_val['emotion']!=1]\n",
    "##data_test = data_test[data_test['emotion']!=1]\n",
    "#data_train['emotion'] = data_train['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "#data_test['emotion'] = data_test['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "#data_val['emotion'] = data_val['emotion'].apply(lambda ele: ele-1 if ele > 0 else ele)\n",
    "print(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ab21f-edc4-43ad-b1c5-b8140c8737d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_labels = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def setup_axe(axe,df,title):\n",
    "    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n",
    "    axe.set_xticklabels(emotion_labels)\n",
    "    axe.set_xlabel(\"Emotions\")\n",
    "    axe.set_ylabel(\"Number\")\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # set individual bar lables using above list\n",
    "    for i in axe.patches:\n",
    "        # get_x pulls left or right; get_height pushes up or down\n",
    "        axe.text(i.get_x()-.05, i.get_height()+120, \\\n",
    "                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n",
    "                    rotation=0)\n",
    "\n",
    "   \n",
    "fig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)\n",
    "setup_axe(axes[0],data_train,'train')\n",
    "setup_axe(axes[1],data_val,'validation')\n",
    "setup_axe(axes[2],data_test,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee8ad0-0c8a-4400-8478-49466cbd72a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initilize parameters\n",
    "num_classes = 7\n",
    "width, height = 48, 48\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "num_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb66cd3-0ef4-4e7c-9a00-2d2012b2ca77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CRNO(df, dataName):\n",
    "    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n",
    "    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width, height,1)/255.0   \n",
    "    data_Y = to_categorical(df['emotion'], num_classes)  \n",
    "    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n",
    "    return data_X, data_Y\n",
    "\n",
    "    \n",
    "train_X, train_Y = CRNO(data_train, \"train\") #training data\n",
    "val_X, val_Y     = CRNO(data_val, \"val\") #validation data\n",
    "test_X, test_Y   = CRNO(data_test, \"test\") #test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc42306-cf40-4961-80d1-6729ac70110b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "data_path = \"C:\\\\Users\\\\vijay\\\\Downloads\\\\archive(6)\\\\CK+48\"\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "numbers = []\n",
    "c=0\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(48,48))\n",
    "        input_img_resize = np.reshape(input_img_resize,(48,48,1))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        c += 1\n",
    "    numbers.append(c)\n",
    "    c = 0\n",
    "        \n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea7433-e574-47a0-9b7c-8ccf4807b206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl = img_data\n",
    "np.reshape(pl[0],(48,48,1))\n",
    "pl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f171144-3435-4fda-a52f-074f6870df24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:134]=0 #135\n",
    "labels[135:188]=6 #54\n",
    "labels[189:365]=1 #177\n",
    "labels[366:440]=2 #75\n",
    "labels[441:647]=3 #207\n",
    "labels[648:731]=4 #84\n",
    "labels[732:980]=5 #249\n",
    "\n",
    "names = ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['Angry','disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd07a5-4fde-4181-9091-e2b1decdf965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import  to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51234924-ed61-4f39-9be6-9971df03669a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(48, 48, 1))\n",
    "    num_filters = 32\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,3, 2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    #outputs = Dense(10, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, t)\n",
    "\n",
    "    return model\n",
    "\n",
    "#output layer\n",
    "#model.add(Dense(6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e281b6a-9925-490b-89d6-788410efd776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f781c5-f1e6-474f-83ec-6bc6ac02a7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from stn import spatial_transformer_network as transformer\n",
    "\n",
    "img_inputs = keras.Input(shape=(48,48,1))\n",
    "\n",
    "locnet = layers.Conv2D(32,3, padding='same')(img_inputs)\n",
    "locnet = layers.MaxPooling2D(3, padding='same')(locnet)\n",
    "locnet = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Conv2D(64,3, padding='same')(locnet)\n",
    "locnet = layers.MaxPooling2D(3, padding='same')(locnet)\n",
    "locnet = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Conv2D(96,3, padding='same')(locnet)\n",
    "feat_map = layers.Activation('relu')(locnet)\n",
    "locnet = layers.BatchNormalization()(locnet)\n",
    "locnet = layers.Flatten()(feat_map)\n",
    "locnet = layers.Dense(90, activation='relu',kernel_regularizer='l2')(locnet)\n",
    "locnet = layers.Dropout(0.2)(locnet)\n",
    "locnet = layers.Dense(32, activation='relu', kernel_regularizer='l2')(locnet)\n",
    "theta = layers.Dense(6, activation='linear')(locnet)\n",
    "\n",
    "locnet = keras.Model(img_inputs, theta, name=\"locnet\")\n",
    "#locnet.summary()\n",
    "\n",
    "#spatial transformer network\n",
    "outstn = transformer(feat_map,theta)\n",
    "\n",
    "\n",
    "\n",
    "#feature extraction network\n",
    "fe = layers.Conv2D(32,3, padding='same')(img_inputs)\n",
    "fe = layers.BatchNormalization()(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "fe = layers.MaxPooling2D(3,padding='same')(fe)\n",
    "fe = layers.Conv2D(64,3, padding='same')(fe)\n",
    "fe = layers.BatchNormalization()(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "fe = layers.MaxPooling2D(3,padding='same')(fe)\n",
    "fe = layers.Conv2D(96,3, padding='same')(fe)\n",
    "fe = layers.Activation('relu')(fe)\n",
    "do = layers.BatchNormalization()(fe)\n",
    "\n",
    "fe = keras.Model(img_inputs, do, name=\"feature extractor\")\n",
    "#fe.summary()\n",
    "\n",
    "add = layers.Add()([outstn, do])\n",
    "\n",
    "flats = layers.Flatten()(add)\n",
    "flats = layers.Dense(64, activation='relu',  kernel_regularizer='l2')(flats)\n",
    "flats = layers.Dropout(0.4)(flats)\n",
    "flats = layers.Dense(32, activation='relu',  kernel_regularizer='l2')(flats)\n",
    "flats = layers.Dropout(0.4)(flats)\n",
    "#output = layers.Dense(6, activation='softmax')(flats)\n",
    "\n",
    "x1 = layers.Dense(7, activation='linear')(flats)\n",
    "x2 = layers.Dense(7,activation='linear')(flats)\n",
    "x3 = layers.Dense(7,activation='linear')(flats)\n",
    "x4 = layers.Dense(7,activation='linear')(flats)\n",
    "avg = layers.Average()([x1, x2, x3, x4])\n",
    "out = layers.Dense(7, activation='softmax')(avg)\n",
    "\n",
    "model = keras.Model(inputs=img_inputs, outputs=out, name=\"FEMSTN\")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr_schedule), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9532547-7021-4c1b-8e42-d3202cfa6956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ghost.hdf5\n",
    "import alpha.hdf5 as Eyebrow_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b595dc-d00a-43a5-8f12-4b4c46eb3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if(ghost.keras.model (True, Maxpool):\n",
    "   checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bfcb7-73f6-4d9f-ae19-9531153801fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import random\n",
    "from twilio.rest import Client\n",
    "\n",
    "account_sid = 'AC1cbb5510c9a09fe576d293357dd4b76b'\n",
    "auth_token = '3ed5835edd3b0287f1bbab1d3e34668c'\n",
    "client = Client(account_sid, auth_token)\n",
    "count = 5\n",
    "\n",
    "def dreamer_now(stress_value):\n",
    "    i = random.randint(1, 100)\n",
    "    message_body = f\"Here are a few happy songs to cheer you up:\\n\\n\"\n",
    "    for j in range(5):\n",
    "        message_body += f\"- {happy_songs[i + j]}\\n\"\n",
    "    message = client.messages.create(\n",
    "        from_ = 'whatsapp:+14155238886',\n",
    "        body = message_body,\n",
    "        to = 'whatsapp:+919551149200'\n",
    "    )\n",
    "    print(message.sid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f97ee-b97c-48cc-b2c2-91212bc38f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "happy_songs = {\n",
    "1: \"Twist and Shout - The Beatles\",\n",
    "2: \"All You Need Is Love - The Beatles\",\n",
    "3: \"A Hard Day's Night - The Beatles\",\n",
    "4: \"Here Comes the Sun - The Beatles\",\n",
    "5: \"Like a Rolling Stone - Bob Dylan\",\n",
    "6: \"The Times They Are A-Changin' - Bob Dylan\",\n",
    "7: \"Blowin' in the Wind - Bob Dylan\",\n",
    "8: \"Lay Lady Lay - Bob Dylan\",\n",
    "9: \"The Thrill Is Gone - BB King\",\n",
    "10: \"Sweet Little Angel - BB King\",\n",
    "11: \"Rock Me Baby - BB King\",\n",
    "12: \"Everyday I Have the Blues - BB King\",\n",
    "13: \"Walking on Sunshine - Katrina and the Waves\",\n",
    "14: \"Don't Stop Believin' - Journey\",\n",
    "15: \"I Wanna Dance with Somebody - Whitney Houston\",\n",
    "16: \"Happy - Pharrell Williams\",\n",
    "17: \"Uptown Funk - Mark Ronson ft. Bruno Mars\",\n",
    "18: \"September - Earth, Wind & Fire\",\n",
    "19: \"I'm a Believer - The Monkees\",\n",
    "20: \"Celebration - Kool & The Gang\",\n",
    "21: \"Dancing Queen - ABBA\",\n",
    "22: \"Hey Ya! - OutKast\",\n",
    "23: \"Can't Stop the Feeling! - Justin Timberlake\",\n",
    "24: \"Girls Just Want to Have Fun - Cyndi Lauper\",\n",
    "25: \"Shake It Off - Taylor Swift\",\n",
    "26: \"I Will Survive - Gloria Gaynor\",\n",
    "27: \"Good Vibrations - The Beach Boys\",\n",
    "28: \"Wake Me Up Before You Go-Go - Wham!\",\n",
    "29: \"I'm Still Standing - Elton John\",\n",
    "30: \"All Star - Smash Mouth\",\n",
    "31: \"You Make My Dreams - Hall & Oates\",\n",
    "32: \"Sweet Caroline - Neil Diamond\",\n",
    "33: \"What a Wonderful World - Louis Armstrong\",\n",
    "34: \"Valerie - Mark Ronson ft. Amy Winehouse\",\n",
    "35: \"Stayin' Alive - Bee Gees\",\n",
    "36: \"Bohemian Rhapsody - Queen\",\n",
    "37: \"I Want You Back - The Jackson 5\",\n",
    "38: \"I Feel Good - James Brown\",\n",
    "39: \"Mamma Mia - ABBA\",\n",
    "40: \"Footloose - Kenny Loggins\",\n",
    "41: \"Ain't No Mountain High Enough - Marvin Gaye & Tammi Terrell\",\n",
    "42: \"Get Lucky - Daft Punk ft. Pharrell Williams\",\n",
    "43: \"You Can't Hurry Love - The Supremes\",\n",
    "44: \"Sweet Child O' Mine - Guns N' Roses\",\n",
    "45: \"Kiss - Prince\",\n",
    "46: \"Dancing in the Street - Martha & The Vandellas\",\n",
    "47: \"Ain't No Sunshine - Bill Withers\",\n",
    "48: \"Three Little Birds - Bob Marley\",\n",
    "49: \"One Love - Bob Marley\",\n",
    "50: \"Could You Be Loved - Bob Marley\",\n",
    "51: \"Tum Se Hi - Jab We Met\",\n",
    "52: \"Tere Bina - Guru\",    \n",
    "53: \"Jai Ho - Slumdog Millionaire\",\n",
    "54: \"Chaiyya Chaiyya - Dil Se\",\n",
    "55: \"Kal Ho Naa Ho - Kal Ho Naa Ho\",\n",
    "56: \"Kabhi Kabhi Mere Dil Mein - Kabhi Kabhie\",\n",
    "57: \"Chand Sifarish - Fanaa\",\n",
    "58: \"Kabhi Jo Baadal Barse - Jackpot\",\n",
    "59: \"Tujh Mein Rab Dikhta Hai - Rab Ne Bana Di Jodi\",\n",
    "60: \"Chhod Do Aanchal Zamana Kya Kahega - Paying Guest\",\n",
    "61: \"Mere Sapno Ki Rani - Aradhana\",\n",
    "62: \"Yeh Dosti - Sholay\",\n",
    "63: \"Aaj Kal Tere Mere Pyaar Ke Charche - Brahmachari\",\n",
    "64: \"Jab Koi Baat Bigad Jaye - Jurm\",\n",
    "65: \"Ae Mere Humsafar - Qayamat Se Qayamat Tak\",\n",
    "66: \"Kajra Re - Bunty Aur Babli\",\n",
    "67: \"Jumma Chumma De De - Hum\",\n",
    "68: \"Dilbar Dilbar - Sirf Tum\",\n",
    "69: \"Mere Rashke Qamar - Baadshaho\",\n",
    "70: \"Tamma Tamma Loge - Thanedaar\",\n",
    "71: \"Dola Re Dola - Devdas\",\n",
    "72: \"Mehendi Laga Ke Rakhna - Dilwale Dulhania Le Jayenge\",\n",
    "73: \"Kuch Kuch Hota Hai - Kuch Kuch Hota Hai\",\n",
    "74: \"Radha - Student of the Year\",\n",
    "75: \"Cham Cham - Baaghi\",\n",
    "76: \"Dil Chori - Sonu Ke Titu Ki Sweety\",\n",
    "77: \"Hawa Hawa - Mubarakan\",\n",
    "78: \"Aankh Marey - Simmba\",\n",
    "79: \"Tum Hi Ho - Aashiqui 2\",\n",
    "80: \"Dheere Dheere - Yo Yo Honey Singh\",\n",
    "81: \"Munni Badnaam Hui - Dabangg\",\n",
    "82: \"Sheila Ki Jawani - Tees Maar Khan\",\n",
    "83: \"Chikni Chameli - Agneepath\",\n",
    "84: \"Balam Pichkari - Yeh Jawaani Hai Deewani\",\n",
    "85: \"Gandi Baat - R... Rajkumar\",\n",
    "86: \"Lungi Dance - Chennai Express\",\n",
    "87: \"Ghagra - Yeh Jawaani Hai Deewani\",\n",
    "88: \"Tune Maari Entriyaan - Gunday\",\n",
    "89: \"Ainvayi Ainvayi - Band Baaja Baaraat\",\n",
    "90: \"Ae Papi - Kismat Konnection\",\n",
    "91: \"Soni De Nakhre - Partner\",\n",
    "92: \"Tu Mere Agal Bagal - Phata Poster Nikhla Hero\",\n",
    "93: \"Kudi Nu Nachne De - Angrezi Medium\",\n",
    "94: \"Milegi Milegi - Stree\",\n",
    "95: \"Duniya Mein Aaye Ho Toh - Judwaa\",\n",
    "96: \"Husn Hai Suhana - Coolie No. 1\",\n",
    "97: \"O Saki Saki - Batla House\",\n",
    "98: \"Hookah Bar - Khiladi 786\",\n",
    "99: \"Billo Rani - Dhan Dhana Dhan Goal\",\n",
    "100: \"Main Aisa Kyun Hoon - Lakshya\"}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b45259-7260-4864-9d58-9e5872814412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed708f3-c088-446a-99b4-2a59069bfce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag = int(input(\"Enter 0 to play the video or 1 to access webcam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f562929-4d46-4114-8c84-1193de0183c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d1a4f-3a33-4b88-8fba-37806c0a8a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def eye_brow_distance(leye,reye):\n",
    "    #global points\n",
    "    distq = dist.euclidean(leye,reye)\n",
    "    points.append(int(distq))\n",
    "    return distq\n",
    "\n",
    "def normalize_values(points,disp):\n",
    "    normalized_value = abs(disp - np.min(points))/abs(np.max(points) - np.min(points))\n",
    "    stress_value = np.exp(-(normalized_value))\n",
    "    if stress_value>=50:\n",
    "        stress_status = \"Current Stress value\"\n",
    "    else:\n",
    "        stress_status = \"Current stress value\"\n",
    "    return stress_value, stress_status\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if flag == 0:\n",
    "    cap = cv2.VideoCapture('WhatsApp Video 2023-04-01 at 12.30.44 PM.mp4')\n",
    "    print('0')    \n",
    "if flag == 1:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('1')\n",
    "points = []\n",
    "while(True):\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width = 500, height = 500)\n",
    "\n",
    "    # preprocessing the image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    detections = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for detection in detections:\n",
    "        x, y, w, h = detection\n",
    "\n",
    "        leye = []\n",
    "        reye = []\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            if ex < w/2:\n",
    "                leye = (int(ex+ew/2+x), int(ey+eh/2+y))\n",
    "                #cv2.circle(frame, leye, 2, (0, 0, 255), 2)\n",
    "            else:\n",
    "                reye = (int(ex+ew/2+x), int(ey+eh/2+y))\n",
    "                #cv2.circle(frame, reye, 2, (0, 0, 255), 2)\n",
    "\n",
    "        if leye and reye:\n",
    "\n",
    "            disp = eye_brow_distance(leye,reye)\n",
    "            stress_value, stress_status = normalize_values(points, disp)\n",
    "            cv2.putText(frame, f\"Stress value: {stress_value :.2f}\", (x, y+h+30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "            while count < 1:\n",
    "                t1 = threading.Thread(target=dreamer_now, args=(stress_value,))\n",
    "                t1.start()\n",
    "                count += 1\n",
    "                t1.join()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
